# FundamentaÃ§Ã£o MatemÃ¡tica - Autoencoders para DetecÃ§Ã£o de Anomalias

## ğŸ§® 1. IntroduÃ§Ã£o TeÃ³rica

### 1.1 O Problema MatemÃ¡tico

A detecÃ§Ã£o de anomalias em trÃ¡fego de rede pode ser formulada como um problema de **estimaÃ§Ã£o de densidade** em alta dimensionalidade. Dado um conjunto de observaÃ§Ãµes normais X_normal âŠ‚ â„áµˆ, queremos aprender uma funÃ§Ã£o f: â„áµˆ â†’ â„âº que estime a densidade p(x) dos dados normais.

**Analogia**: Como um sommelier que aprende a identificar vinhos de qualidade. ApÃ³s provar muitos vinhos excelentes, consegue detectar quando algo estÃ¡ "fora do padrÃ£o" - mesmo sem nunca ter provado aquele defeito especÃ­fico.

### 1.2 LimitaÃ§Ãµes de MÃ©todos Tradicionais

#### Curse of Dimensionality
Em espaÃ§os de alta dimensÃ£o (d >> 1), mÃ©todos baseados em distÃ¢ncia falham:

```
Volume da esfera unitÃ¡ria em d dimensÃµes:
V_d = Ï€^(d/2) / Î“(d/2 + 1)

Para d >> 1: V_d â†’ 0
```

**ImplicaÃ§Ã£o**: Pontos ficam uniformemente distantes, perdendo discriminaÃ§Ã£o.

#### EstimaÃ§Ã£o ParamÃ©trica vs. NÃ£o-paramÃ©trica

| MÃ©todo | Vantagens | Desvantagens |
|--------|-----------|--------------|
| **ParamÃ©trico** (Gaussian) | Eficiente, interpretÃ¡vel | Assume distribuiÃ§Ã£o especÃ­fica |
| **NÃ£o-paramÃ©trico** (KDE) | FlexÃ­vel | Curse of dimensionality |
| **Neural** (Autoencoder) | Aprende manifolds | Black-box, requer dados |

## ğŸ”¬ 2. Teoria dos Autoencoders

### 2.1 DefiniÃ§Ã£o Formal

Um autoencoder Ã© um par de funÃ§Ãµes (f_enc, f_dec) que minimizam a distÃ¢ncia entre entrada e reconstruÃ§Ã£o:

```
Encoder: f_enc: â„áµˆ â†’ â„áµ, h = f_enc(x)
Decoder: f_dec: â„áµ â†’ â„áµˆ, xÌ‚ = f_dec(h)

Objetivo: min_Î¸ ğ”¼[||x - f_dec(f_enc(x))||Â²]
```

onde k << d (bottleneck) forÃ§a aprendizado de representaÃ§Ã£o compacta.

### 2.2 Manifold Learning Perspective

#### HipÃ³tese do Manifold

Dados reais frequentemente residem em **manifolds de baixa dimensionalidade** embebidos em espaÃ§os de alta dimensÃ£o:

```
X âŠ‚ M âŠ‚ â„áµˆ, onde dim(M) = k << d
```

**Analogia**: Como uma folha de papel (2D) amassada no espaÃ§o 3D. O papel mantÃ©m sua estrutura bidimensional intrÃ­nseca, mesmo deformado no espaÃ§o maior.

#### Autoencoder como Aproximador de Manifold

O encoder aprende uma **funÃ§Ã£o de projeÃ§Ã£o** Ï†: M â†’ â„áµ, e o decoder aprende a **funÃ§Ã£o inversa** Ïˆ: â„áµ â†’ M.

Para pontos x âˆˆ M (normais):
```
||x - Ïˆ(Ï†(x))||Â² â‰ˆ 0
```

Para pontos x âˆ‰ M (anÃ´malos):
```
||x - Ïˆ(Ï†(x))||Â² >> 0
```

### 2.3 Capacidade e GeneralizaÃ§Ã£o

#### Universal Approximation Theorem

Redes neurais com uma camada oculta podem aproximar qualquer funÃ§Ã£o contÃ­nua, mas:

1. **Largura necessÃ¡ria** pode ser exponencial na dimensÃ£o
2. **OtimizaÃ§Ã£o** pode nÃ£o encontrar o mÃ­nimo global
3. **GeneralizaÃ§Ã£o** depende da complexidade dos dados

#### Bias-Variance Tradeoff

- **Underfitting** (high bias): Modelo muito simples, erro alto em treino e teste
- **Overfitting** (high variance): Modelo muito complexo, erro baixo em treino, alto em teste
- **Sweet spot**: BalanÃ§o Ã³timo via regularizaÃ§Ã£o e validaÃ§Ã£o

**Analogia**: Como uma roupa - muito apertada (underfitting) nÃ£o serve, muito larga (overfitting) nÃ£o define bem a forma. O tamanho certo fica perfeito.

## ğŸ“Š 3. MatemÃ¡tica da DetecÃ§Ã£o de Anomalias

### 3.1 Reconstruction Error como MÃ©trica

#### DefiniÃ§Ã£o
Para uma observaÃ§Ã£o x, o erro de reconstruÃ§Ã£o Ã©:

```
RE(x) = ||x - f_dec(f_enc(x))||Â²
```

onde ||Â·|| pode ser norma L2, L1, ou outras mÃ©tricas.

#### Propriedades EstatÃ­sticas

Para dados normais X_normal ~ p_normal(x):

```
RE_normal = {RE(x_i) : x_i âˆˆ X_normal}
```

**Assumindo** RE_normal segue uma distribuiÃ§Ã£o conhecida (ex: Gamma), podemos calcular quantis:

```
Ï„_Î± = Q_Î±(RE_normal)
```

onde Q_Î± Ã© o quantil Î± da distribuiÃ§Ã£o.

### 3.2 Threshold Selection

#### Abordagem EstatÃ­stica

1. **MÃ©todo do Percentil**:
   ```
   Ï„ = percentile(RE_normal, Î±)
   Exemplo: Î± = 95% â†’ 5% falsos positivos esperados
   ```

2. **MÃ©todo Ïƒ-multiplier**:
   ```
   Ï„ = Î¼(RE_normal) + kÂ·Ïƒ(RE_normal)
   Exemplo: k = 2.5 â†’ Chebyshev bound
   ```

3. **MÃ©todo da MÃ¡xima VerossimilhanÃ§a**:
   ```
   Assumir RE_normal ~ Gamma(Î±, Î²)
   Estimar parÃ¢metros via MLE
   Ï„ = Q_p(Gamma(Î±Ì‚, Î²Ì‚))
   ```

#### Trade-off Fundamental

```
Precision = TP / (TP + FP)
Recall = TP / (TP + FN)

Threshold â†‘: Precision â†‘, Recall â†“
Threshold â†“: Precision â†“, Recall â†‘
```

**Analogia**: Como ajustar a sensibilidade de um detector de metal. Muito sensÃ­vel encontra tudo (alto recall), mas tambÃ©m lixo (baixo precision). Pouco sensÃ­vel perde tesouros (baixo recall), mas o que encontra Ã© valioso (alto precision).

### 3.3 AnÃ¡lise ROC e PR

#### Curva ROC (Receiver Operating Characteristic)

```
TPR = TP / (TP + FN)  (Sensitivity)
FPR = FP / (FP + TN)  (1 - Specificity)

AUC_ROC = âˆ«â‚€Â¹ TPR(FPR) d(FPR)
```

**InterpretaÃ§Ã£o**: Probabilidade de classificar corretamente um par (normal, anÃ´malo) escolhido aleatoriamente.

#### Curva Precision-Recall

```
Precision = TP / (TP + FP)
Recall = TP / (TP + FN)

AUC_PR = âˆ«â‚€Â¹ Precision(Recall) d(Recall)
```

**Vantagem para dados desbalanceados**: Foca no desempenho na classe minoritÃ¡ria (anomalias).

## ğŸ—ï¸ 4. Arquitetura e Design

### 4.1 Dimensionamento do Bottleneck

#### AnÃ¡lise via PCA

O PCA fornece uma baseline para o dimensionamento:

```
X = UÎ£V^T

VariÃ¢ncia explicada pelos primeiros k componentes:
RÂ²(k) = Î£áµ¢â‚Œâ‚áµ Ïƒáµ¢Â² / Î£áµ¢â‚Œâ‚áµˆ Ïƒáµ¢Â²
```

**Regra prÃ¡tica**: Escolher k tal que RÂ²(k) â‰¥ 0.95.

#### Information Theory Perspective

O bottleneck forÃ§a **compressÃ£o com perda**:

```
I(X; H) â‰¤ H(H) â‰¤ kÂ·logâ‚‚(n_neurons)
```

onde I(X; H) Ã© a informaÃ§Ã£o mÃºtua entre entrada e representaÃ§Ã£o oculta.

**Analogia**: Como fazer uma mala - sÃ³ cabe o essencial. O autoencoder aprende quais aspectos dos dados sÃ£o "essenciais" para reconstruÃ§Ã£o.

### 4.2 FunÃ§Ã£o de AtivaÃ§Ã£o

#### ReLU vs. Alternatives

```
ReLU: f(x) = max(0, x)
Leaky ReLU: f(x) = max(Î±x, x), Î± âˆˆ (0, 1)
ELU: f(x) = x if x > 0, Î±(e^x - 1) if x â‰¤ 0
```

**Para autoencoders**:
- **Encoder**: ReLU (sparsity, computational efficiency)
- **Decoder final**: Linear (permite valores negativos na reconstruÃ§Ã£o)

#### NormalizaÃ§Ã£o

**Batch Normalization**:
```
BN(x) = Î³Â·(x - Î¼)/Ïƒ + Î²
```

**BenefÃ­cios**: Estabiliza gradientes, acelera convergÃªncia, regularizaÃ§Ã£o implÃ­cita.

### 4.3 FunÃ§Ã£o de Perda

#### Mean Squared Error (MSE)

```
L_MSE = (1/n)Î£áµ¢â‚Œâ‚â¿ ||xáµ¢ - xÌ‚áµ¢||Â²
```

**Vantagens**: DiferenciÃ¡vel, penaliza outliers quadraticamente.
**Desvantagens**: SensÃ­vel a outliers extremos.

#### Mean Absolute Error (MAE)

```
L_MAE = (1/n)Î£áµ¢â‚Œâ‚â¿ ||xáµ¢ - xÌ‚áµ¢||â‚
```

**Vantagens**: Robusto a outliers.
**Desvantagens**: NÃ£o diferenciÃ¡vel em 0, gradientes constantes.

#### Huber Loss (Hybrid)

```
L_Huber = {
  (1/2)(x - xÌ‚)Â² if |x - xÌ‚| â‰¤ Î´
  Î´|x - xÌ‚| - (1/2)Î´Â² if |x - xÌ‚| > Î´
}
```

**BenefÃ­cio**: Combina robustez (MAE) com suavidade (MSE).

## ğŸ“ˆ 5. OtimizaÃ§Ã£o e ConvergÃªncia

### 5.1 Gradient Descent Variants

#### Adam Optimizer

```
m_t = Î²â‚m_{t-1} + (1-Î²â‚)g_t
v_t = Î²â‚‚v_{t-1} + (1-Î²â‚‚)g_tÂ²

mÌ‚_t = m_t/(1-Î²â‚^t)
vÌ‚_t = v_t/(1-Î²â‚‚^t)

Î¸_{t+1} = Î¸_t - Î±Â·mÌ‚_t/(âˆšvÌ‚_t + Îµ)
```

**ParÃ¢metros tÃ­picos**: Î±=0.001, Î²â‚=0.9, Î²â‚‚=0.999, Îµ=10â»â¸

**Analogia**: Como um esquiador descendo uma montanha na neblina. O momento (m_t) mantÃ©m a direÃ§Ã£o geral, a adaptaÃ§Ã£o (v_t) ajusta a velocidade baseada na inclinaÃ§Ã£o local.

### 5.2 RegularizaÃ§Ã£o

#### Weight Decay (L2 Regularization)

```
L_total = L_reconstruction + Î»Â·Î£_i Î¸áµ¢Â²
```

**Efeito**: Penaliza pesos grandes, forÃ§a suavidade na funÃ§Ã£o aprendida.

#### Dropout

```
During training: y = f(x âŠ™ mask), mask ~ Bernoulli(p)
During inference: y = pÂ·f(x)
```

**BenefÃ­cio**: Reduz co-adaptaÃ§Ã£o entre neurÃ´nios, melhora generalizaÃ§Ã£o.

#### Early Stopping

Monitora erro de validaÃ§Ã£o:
```
if val_loss[t] > val_loss[t-patience]:
    stop_training()
```

**Analogia**: Como estudar para uma prova - hÃ¡ um ponto Ã³timo onde parar de estudar evita "overtraining" e cansaÃ§o mental.

### 5.3 Learning Rate Scheduling

#### Decaimento Exponencial

```
lr(t) = lrâ‚€Â·Î³^t, onde Î³ âˆˆ (0, 1)
```

#### Cosine Annealing

```
lr(t) = lr_min + (lr_max - lr_min)Â·(1 + cos(Ï€t/T))/2
```

**Vantagem**: Permite "re-aquecimento" para escapar de mÃ­nimos locais.

## ğŸ¯ 6. MÃ©tricas de AvaliaÃ§Ã£o AvanÃ§adas

### 6.1 Silhouette Score para RepresentaÃ§Ãµes

```
s(i) = (b(i) - a(i)) / max{a(i), b(i)}

onde:
a(i) = distÃ¢ncia mÃ©dia para pontos da mesma classe
b(i) = distÃ¢ncia mÃ©dia para pontos da classe mais prÃ³xima
```

**InterpretaÃ§Ã£o**: s âˆˆ [-1, 1], valores prÃ³ximos de 1 indicam boa separaÃ§Ã£o.

### 6.2 Calinski-Harabasz Index

```
CH = (trace(B_k)/(k-1)) / (trace(W_k)/(n-k))

onde:
B_k = between-cluster sum of squares
W_k = within-cluster sum of squares
```

**InterpretaÃ§Ã£o**: RazÃ£o entre dispersÃ£o inter-cluster e intra-cluster.

### 6.3 Adjusted Rand Index (ARI)

```
ARI = (RI - E[RI]) / (max(RI) - E[RI])
```

onde RI Ã© o Rand Index e E[RI] Ã© seu valor esperado.

**BenefÃ­cio**: Corrigido para concordÃ¢ncia casual, ARI âˆˆ [-1, 1].

## ğŸ”§ 7. Aspectos Computacionais

### 7.1 Complexidade Temporal

#### Forward Pass
```
Encoder: O(dÂ·hâ‚ + hâ‚Â·hâ‚‚ + ... + h_{n-1}Â·k)
Decoder: O(kÂ·h_{n-1} + ... + hâ‚‚Â·hâ‚ + hâ‚Â·d)

Total: O(dÂ·Î£háµ¢ + kÂ·Î£háµ¢)
```

#### Backward Pass (Backpropagation)
Complexidade similar ao forward pass, mas com overhead adicional para cÃ¡lculo de gradientes.

### 7.2 Complexidade Espacial

```
MemÃ³ria para pesos: O(dÂ·hâ‚ + Î£áµ¢háµ¢Â·háµ¢â‚Šâ‚ + hâ‚™Â·k)
MemÃ³ria para ativaÃ§Ãµes (batch B): O(BÂ·Î£háµ¢)
```

### 7.3 ParalelizaÃ§Ã£o

#### Mini-batch Processing
```
Batch size B: balanÃ§o entre:
- Gradiente mais estÃ¡vel (B â†‘)
- Menor uso de memÃ³ria (B â†“)
- Maior paralelizaÃ§Ã£o (B â†‘)
```

**Regra prÃ¡tica**: B âˆˆ [16, 128] para a maioria dos casos.

## ğŸŒŠ 8. AnÃ¡lise de ConvergÃªncia

### 8.1 Landscape de Perda

#### Problema Non-convex

FunÃ§Ã£o de perda de redes neurais Ã© **nÃ£o-convexa**:
- MÃºltiplos mÃ­nimos locais
- PlatÃ´s e saddle points
- Garantias de convergÃªncia limitadas

#### Teorema de ConvergÃªncia (Simplificado)

Para step size apropriado Î±:
```
lim_{tâ†’âˆ} ||âˆ‡L(Î¸_t)|| = 0
```

**InterpretaÃ§Ã£o**: ConvergÃªncia para ponto crÃ­tico (nÃ£o necessariamente mÃ­nimo global).

### 8.2 EstratÃ©gias para MÃ­nimos Locais

1. **MÃºltiplas InicializaÃ§Ãµes**: Random restarts
2. **Momentum**: Escapar de vales rasos
3. **Learning Rate Scheduling**: Refinamento fino
4. **Ensemble**: Combinar mÃºltiplos modelos

**Analogia**: Como procurar o ponto mais baixo em uma cordilheira montanhosa usando mÃºltiplos helicÃ³pteros (inicializaÃ§Ãµes) e diferentes estratÃ©gias de busca.

## ğŸ¨ 9. Interpretabilidade MatemÃ¡tica

### 9.1 Feature Attribution

#### Gradient-based Methods

```
Attribution(xáµ¢) = âˆ‚L/âˆ‚xáµ¢
```

**InterpretaÃ§Ã£o**: Quanto a mudanÃ§a em xáµ¢ afeta a perda.

#### Integrated Gradients

```
IG(xáµ¢) = (xáµ¢ - x'áµ¢) Ã— âˆ«â‚€Â¹ âˆ‚L/âˆ‚x|_{x'+(x-x')t} dt
```

onde x' Ã© uma baseline (ex: zero vector).

### 9.2 AnÃ¡lise do EspaÃ§o Latente

#### t-SNE para VisualizaÃ§Ã£o

```
Minimizar: KL(P||Q) = Î£áµ¢â±¼ páµ¢â±¼ log(páµ¢â±¼/qáµ¢â±¼)

onde:
páµ¢â±¼ = similaridade em alta dimensÃ£o
qáµ¢â±¼ = similaridade em baixa dimensÃ£o
```

#### UMAP (Uniform Manifold Approximation)

```
Objective: min âˆ‘áµ¢â±¼ wáµ¢â±¼ log(wáµ¢â±¼/qáµ¢â±¼) + (1-wáµ¢â±¼)log((1-wáµ¢â±¼)/(1-qáµ¢â±¼))
```

**Vantagem**: Preserva estrutura global e local melhor que t-SNE.

## ğŸ”® 10. ExtensÃµes TeÃ³ricas

### 10.1 Variational Autoencoders (VAE)

#### Framework ProbabilÃ­stico

```
Encoder: q_Ï†(z|x) â‰ˆ p(z|x)
Decoder: p_Î¸(x|z)
Prior: p(z) = N(0, I)

Loss: L = E[log p_Î¸(x|z)] - KL(q_Ï†(z|x)||p(z))
```

**BenefÃ­cio**: GeraÃ§Ã£o de amostras, incerteza quantificada.

### 10.2 Adversarial Autoencoders

#### Min-max Game

```
Generator (Decoder): min_G L_reconstruction
Discriminator: max_D L_adversarial

Total: min_G max_D V(D,G)
```

**BenefÃ­cio**: Prior mais flexÃ­vel que Gaussian.

### 10.3 Transformer-based Autoencoders

#### Self-attention Mechanism

```
Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V

MultiHead = Concat(headâ‚,...,head_h)W^O
```

**AplicaÃ§Ã£o**: SequÃªncias temporais de trÃ¡fego de rede.

## ğŸ“š 11. ConexÃµes com Outras Ãreas

### 11.1 Information Theory

#### Mutual Information

```
I(X;Z) = âˆ«âˆ« p(x,z) log(p(x,z)/(p(x)p(z))) dxdz
```

**InterpretaÃ§Ã£o**: Quantidade de informaÃ§Ã£o compartilhada entre entrada e representaÃ§Ã£o.

#### Rate-Distortion Theory

```
R(D) = min_{p(áº‘|z):E[d(z,áº‘)]â‰¤D} I(Z;áº)
```

**AplicaÃ§Ã£o**: Trade-off entre compressÃ£o (rate) e qualidade (distortion).

### 11.2 Differential Geometry

#### Riemannian Manifolds

```
Metric tensor: g_ij = âˆ‚Ï†/âˆ‚u^i Â· âˆ‚Ï†/âˆ‚u^j
```

**ConexÃ£o**: Autoencoder aprende mapeamento entre manifolds Riemannianos.

### 11.3 Control Theory

#### Stability Analysis

```
Sistema dinÃ¢mico: Î¸_{t+1} = Î¸_t - Î±âˆ‡L(Î¸_t)

Estabilidade de Lyapunov: V(Î¸) â‰¥ 0, VÌ‡(Î¸) â‰¤ 0
```

## ğŸ 12. ConclusÃµes MatemÃ¡ticas

### 12.1 Teoremas Fundamentais

1. **Universal Approximation**: Capacidade expressiva suficiente
2. **Manifold Learning**: FundamentaÃ§Ã£o geomÃ©trica
3. **ConvergÃªncia**: Garantias sob condiÃ§Ãµes especÃ­ficas
4. **GeneralizaÃ§Ã£o**: Bounds via teoria PAC-learning

### 12.2 LimitaÃ§Ãµes TeÃ³ricas

1. **NÃ£o-convexidade**: Sem garantias de Ã³timo global
2. **Curse of Dimensionality**: Ainda presente em espaÃ§os intermediÃ¡rios
3. **Interpretabilidade**: Trade-off com performance
4. **Robustez**: Sensibilidade a perturbaÃ§Ãµes adversariais

### 12.3 DireÃ§Ãµes Futuras

1. **Teoria de OtimizaÃ§Ã£o**: Novos algoritmos para landscapes nÃ£o-convexos
2. **Geometria Diferencial**: MÃ©tricas adaptativas para manifolds
3. **Teoria da InformaÃ§Ã£o**: Bounds mais apertados para compressÃ£o
4. **Robustez TeÃ³rica**: Garantias formais contra adversÃ¡rios

---

**Nota**: Esta fundamentaÃ§Ã£o matemÃ¡tica serve como base teÃ³rica sÃ³lida para o desenvolvimento e anÃ¡lise do sistema de detecÃ§Ã£o de anomalias proposto. Cada conceito foi escolhido por sua relevÃ¢ncia direta ao problema e implementaÃ§Ã£o prÃ¡tica.